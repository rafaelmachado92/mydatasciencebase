# -*- coding: utf-8 -*-
"""Trabalho_Analise_Preditiva_Avancada.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dWOP-XicGnEd2ROzIG0b1NkOaVzbahag

# Trabalho para a conclusão da disciplina de Análise Preditiva Avançada
## Autor: Rafael Machado##
Matricula: A57612198

#Instalação de bilbiotecas
pip install sklearn
pip install keras
pip install tensorflow
pip install matplotlib
"""

import keras
from keras.datasets import mnist 
from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D
from keras.models import Sequential
from keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt
from keras.callbacks import History
from keras.layers import Dropout
from sklearn.ensemble import RandomForestClassifier
from matplotlib import pyplot 
from sklearn.datasets import fetch_openml
import tensorflow as tf
from sklearn.metrics import accuracy_score
from sklearn.model_selection import RandomizedSearchCV
seed (1234)
digito= mnist.load_data()

numero =tf.keras.datasets.mnist
(training_images, training_labels),(test_images,test_labels)=numero.load_data()
for i in range(9):
    pyplot.subplot(330+1+i)
    pyplot.imshow(training_images[i])

(x_treino,y_treino), (x_teste,y_teste) = mnist.load_data()

x_treino = x_treino.reshape(-1, 28,28, 1)
x_teste = x_teste.reshape(-1, 28,28, 1)

x_treino = x_treino.astype('float32')
x_teste = x_teste.astype('float32')

x_treino_norm = x_treino / 255
x_teste_norm = x_teste / 255

y_treino_cat = to_categorical(y_treino)
y_teste_cat = to_categorical(y_teste)


batch_size=64
epoch=50

x_treino.shape ,y_treino_cat.shape

"""Modelo"""

model = Sequential()
# 1 camada#
model.add(Conv2D(64, (3,3), input_shape=(28, 28, 1)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
# 2 camada#
model.add(Conv2D(64, (3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
# 3 camada#
model.add(Flatten())
model.add(Dense(64))
# 4 camada#
model.add(Dense(10))
model.add(Activation('softmax'))

model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])
modelo =model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])

"""Modelo Sem Normalização"""

history= model.fit(x_treino, y_treino_cat, batch_size=batch_size, epochs=epoch)

test_loss, test_acc = model.evaluate(x_teste, y_teste_cat)
print('Test loss', test_loss)
print('Test accuracy', test_acc)
loss_semnormalizacao=test_loss
accurancy_semnormalizacao = test_acc 
predictions = model.predict(x_teste)

print(np.argmax(np.round(predictions[6])))

plt.imshow(x_teste[6].reshape(28, 28), cmap = plt.cm.binary)
plt.show()

"""Modelo Com Normalização"""

model.fit(x_treino_norm, y_treino_cat, batch_size=batch_size, epochs=epoch)

test_loss, test_acc = model.evaluate(x_teste_norm, y_teste_cat)
print('Test loss', test_loss)
print('Test accuracy', test_acc)
loss_comnormalizacao =test_loss 
accurancy_comnormalizacao =test_acc 
predictions = model.predict(x_teste)
print(np.argmax(np.round(predictions[5])))

plt.imshow(x_teste[5].reshape(28, 28), cmap = plt.cm.binary)
plt.show()

"""Adicionando mais camadas ao modelo"""

model = Sequential()
# 8 camadas#

model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))
model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))
model.add(Dense(10, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])
modelo =model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])

"""Modelo com Mais camadas e sem normalizacao"""

history= model.fit(x_treino, y_treino_cat, batch_size=batch_size, epochs=epoch)

test_loss, test_acc = model.evaluate(x_teste, y_teste_cat)
print('Test loss', test_loss)
print('Test accuracy', test_acc)
loss_semnormalizacao_mais_camadas=test_loss
accurancy_semnormalizacao_mais_camadas = test_acc 
predictions = model.predict(x_teste)

print(np.argmax(np.round(predictions[9])))

plt.imshow(x_teste[9].reshape(28, 28), cmap = plt.cm.binary)
plt.show()

"""Modelo com Mais camadas e com normalizacao"""

model.fit(x_treino_norm, y_treino_cat, batch_size=batch_size, epochs=epoch)

test_loss, test_acc = model.evaluate(x_teste_norm, y_teste_cat)
print('Test loss', test_loss)
print('Test accuracy', test_acc)
loss_comnormalizacao_mais_camadas =test_loss 
accurancy_comnormalizacao_mais_camadas =test_acc 
predictions = model.predict(x_teste)
print(np.argmax(np.round(predictions[3])))

plt.imshow(x_teste[3].reshape(28, 28), cmap = plt.cm.binary)
plt.show()

a="%0.4f" % loss_semnormalizacao
b="%0.4f" % loss_comnormalizacao
c="%0.4f" % loss_semnormalizacao_mais_camadas
d="%0.4f" % loss_comnormalizacao_mais_camadas

semnormalizacao_pouca_camada="%0.4f" % accurancy_semnormalizacao
comnormalizacao_pouca_camada="%0.4f" % accurancy_comnormalizacao
semnormalizacao_mais_camada="%0.4f" % accurancy_semnormalizacao_mais_camadas
comnormalizacao_mais_camada="%0.4f" % accurancy_comnormalizacao_mais_camadas

print("Os resultados SEM normalização são ",(semnormalizacao_pouca_camada) ,"para precisão e",(a) ,"para perda" )
print("Os resultados COM normalização são ",(comnormalizacao_pouca_camada) ,"para precisão e",(b) ,"para perda" )
print("Os resultados SEM normalização e mais camadas são ",(semnormalizacao_mais_camada) ,"para precisão e",(c) ,"para perda" )
print("Os resultados COM normalização e mais camadas são ",(comnormalizacao_mais_camada) ,"para precisão e",(d) ,"para perda" )

"""Portanto é melhor mais camadas com resultados normalizados.

Analise com Random Forest
"""

mnist = fetch_openml('MNIST_784', version=1, cache=True)
mnist.target = mnist.target.astype(np.int8)

x, y = mnist["data"], mnist["target"]
x.shape, y.shape
split_index = 60000
x_treinorf, x_testerf = x[:split_index], x[split_index:]
y_treinorf, y_testerf = y[:split_index], y[split_index:]
x_treinorf.shape, y_treinorf.shape, x_testerf.shape, y_testerf.shape

forest = RandomForestClassifier(random_state=50, n_estimators = 10)

forest.fit(x_treinorf, y_treinorf)

y_pred = forest.predict(x_testerf)
accuracy_score(y_testerf, y_pred)

forest_hp_tuning=RandomForestClassifier(random_state=50, n_estimators = 10)
forest_hp_tuning.get_params()

parameters = {'n_estimators':[5,25,125,250,500,1000],
              'bootstrap':[False, True],
              'min_samples_split':[2,4,8,16],
              'max_depth':[10,100,1000,None]}
clf = RandomizedSearchCV(forest_hp_tuning, param_distributions=parameters,
                                n_iter=1, cv=2, scoring='accuracy', random_state=50)

clf.fit(x_treinorf, y_treinorf)

cvres = clf.cv_results_
for mean_score, params in zip(cvres["mean_test_score"], cvres["params"]):
    print(mean_score, params)
    rfr=mean_score
    randomforest_result=str(rfr)

"""Escolhendo o Melhor modelo"""

lista=(randomforest_result,semnormalizacao_pouca_camada,comnormalizacao_pouca_camada,semnormalizacao_mais_camada,comnormalizacao_mais_camada)
maximo=max(lista)
print("O melhor resultado obtido foi de ",maximo, "para acuracidade")

valor = maximo
pos = -1
for i in range(len(lista)-1,-1,-1):
    if lista[i] == valor:
     pos = i+1
if pos==5:
   resposta='comnormalizacao_mais_camada'
elif pos==4:
    resposta='semnormalizacao_mais_camada'
elif pos==3:
    resposta='comnormalizacao_pouca_camada'
elif pos==2:
    resposta='semnormalizacao_pouca_camada'
elif pos==1:
    resposta='randomforest_result'
print('O melhor modelo foi o :',resposta)
print('Sua acuracidade foi de  :',maximo)

"""O aumento de número de camdas interna ajudou na melhora do resultado. A critica fica com o pequeno aumento em relação ao tempo de processamento. Nao se faria necessário pelo incremento, sendo assim, manteria com as 4 camadas iniciais.

Quando falamos do Random Forest, variando seus parametros como arvores, o melhor resultado foi com 125 árvores e apenas 96% de precisão. Não seria o modelo escolhido.
"""